{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c697ed",
   "metadata": {},
   "source": [
    "# Prompt Engineering and Probing with GPT3\n",
    "\n",
    "For the extra-credit, we will be exploring the recent trend that has revolutionalized this field. With GPT3, we can do a variety of tasks without the need of training a model. All we need to do is convert the task into an text generation task that follows a set of instructions called *prompts*. As an example, the task of sentiment classification can be designed as:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "The GPT3 model then completes the text above with the response **Positive**. The above prompt is an example of zero-shot prediction, meaning, we are not providing any signal/direction that can guide the decision. We could also design the prompt as follows:\n",
    "\n",
    "```\n",
    "Decide whether a Tweet's sentiment is positive, neutral, or negative.\n",
    "\n",
    "Tweet: I really liked the Spiderman movie!\n",
    "Sentiment: Positive\n",
    "\n",
    "Tweet: I loved the new Batman movie!\n",
    "Sentiment:\n",
    "```\n",
    "\n",
    "Now this is an example of 1-shot learning, i.e., you are providing an labeled example of how the output should look and then ask GPT3 to complete the next example. When you use more than 1 labeled example, it is known as few-shot learning.  The expectation is that, if you provide more examples in the prompt, it will make better predictions.\n",
    "\n",
    "## Getting Started\n",
    "In this assignment, we will first need to register for an account at: https://beta.openai.com/ As a free trial, you will get $18 credits to make api calls to the GPT3 server. Once registered, you should go through the docs here: https://beta.openai.com/docs/guides/completion/prompt-design to get more info on the capabilities of the model. You can then go directly interact with GPT3 in the playground: https://beta.openai.com/playground. For making these calls programmatically, we will do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f6bf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (1.23.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 2)) (4.64.1)\n",
      "Requirement already satisfied: torch in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (1.12.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.6.1-py3-none-any.whl (441 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->-r requirements.txt (line 2)) (0.4.6)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 3)) (4.1.1)\n",
      "Requirement already satisfied: requests in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from transformers->-r requirements.txt (line 4)) (21.3)\n",
      "Collecting huggingface-hub<1.0,>=0.10.0\n",
      "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (6.0)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 4)) (2022.3.15)\n",
      "Requirement already satisfied: pandas in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from datasets->-r requirements.txt (line 5)) (1.4.2)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.14-py39-none-any.whl (132 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from datasets->-r requirements.txt (line 5)) (3.8.1)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-3.1.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Collecting dill<0.3.6\n",
      "  Downloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
      "Collecting responses<0.19\n",
      "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
      "Collecting pyarrow>=6.0.0\n",
      "  Downloading pyarrow-10.0.0-cp39-cp39-win_amd64.whl (20.0 MB)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from datasets->-r requirements.txt (line 5)) (2022.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 4)) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 4)) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 4)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests->transformers->-r requirements.txt (line 4)) (2021.10.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.6.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (5.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from aiohttp->datasets->-r requirements.txt (line 5)) (1.2.0)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.13-py39-none-any.whl (132 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from pandas->datasets->-r requirements.txt (line 5)) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas->datasets->-r requirements.txt (line 5)) (1.16.0)\n",
      "Installing collected packages: dill, xxhash, tokenizers, responses, pyarrow, multiprocess, huggingface-hub, transformers, datasets\n",
      "Successfully installed datasets-2.6.1 dill-0.3.5.1 huggingface-hub-0.10.1 multiprocess-0.70.13 pyarrow-10.0.0 responses-0.18.0 tokenizers-0.13.2 transformers-4.24.0 xxhash-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "806993a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: tqdm in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from openai) (4.64.1)\n",
      "Collecting pandas-stubs>=1.1.0.11\n",
      "  Downloading pandas_stubs-1.5.1.221024-py3-none-any.whl (144 kB)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from openai) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from openai) (4.1.1)\n",
      "Requirement already satisfied: pandas>=1.2.3 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from openai) (1.4.2)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from openai) (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from pandas>=1.2.3->openai) (2021.3)\n",
      "Collecting types-pytz>=2022.1.1\n",
      "  Downloading types_pytz-2022.6.0.1-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.3->openai) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rushi\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\rushi\\appdata\\roaming\\python\\python39\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Building wheels for collected packages: openai\n",
      "  Building wheel for openai (PEP 517): started\n",
      "  Building wheel for openai (PEP 517): finished with status 'done'\n",
      "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55865 sha256=be21941fc5c73857f421b2b5a61bced41f6d35582ce9d7b56dda991442d4dad5\n",
      "  Stored in directory: c:\\users\\rushi\\appdata\\local\\pip\\cache\\wheels\\cf\\3e\\68\\12229a483d9f6efc576a87b40034451b1fcaee5bd8c24b6de9\n",
      "Successfully built openai\n",
      "Installing collected packages: types-pytz, pandas-stubs, openai\n",
      "Successfully installed openai-0.25.0 pandas-stubs-1.5.1.221024 types-pytz-2022.6.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf90729c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "## Find the API key by clicking on your profile in the openai page. Add the key to the environment as following:\n",
    "## Make sure to delete this cell afterwords\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce117de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  model=\"text-davinci-002\",\n",
    "  prompt=\"Decide whether a Tweet's sentiment is positive, neutral, or negative.\\n\\nTweet: \\\"I loved the new Batman movie!\\\"\\nSentiment:\",\n",
    "  temperature=0,\n",
    "  max_tokens=60,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0.5,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1900d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-6A9AOvhcCzWni8wmN95grAz7kC3cm at 0x207ea99edb0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \" Positive\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1667876536,\n",
       "  \"id\": \"cmpl-6A9AOvhcCzWni8wmN95grAz7kC3cm\",\n",
       "  \"model\": \"text-davinci-002\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 1,\n",
       "    \"prompt_tokens\": 31,\n",
       "    \"total_tokens\": 32\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6444ebbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Positive'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['choices'][0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd0af83",
   "metadata": {},
   "source": [
    "If you see ' Positive' as response in the above cell, you have successfully set-up gpt3 in your system.\n",
    "\n",
    "Now, the task for the assignment is really just do something cool. For example, you could probe how well GPT3 performs on the tasks in the previous HWs. Or, you could do something like question-answering or summarization, that were not covered in the assignments. The choice is yours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31660025",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Please submit a written report of what task you tried probing, how well did GPT3 do for that task and what were your key takeaways in this experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330bd30d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
